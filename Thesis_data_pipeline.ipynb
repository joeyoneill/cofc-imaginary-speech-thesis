{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8nnUDCQX97EY"
      },
      "outputs": [],
      "source": [
        "# Created by Joey O'Neill\n",
        "# College of Charleston\n",
        "# Classification Comparison of Deep Learning Models on an Imaginary Speech EEG Dataset\n",
        "# July 2022\n",
        "# URL: https://www.researchgate.net/publication/361728491_Classification_Comparison_of_Deep_Learning_Models_on_an_Imaginary_Speech_EEG_Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports for pipeline\n",
        "import glob\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tempfile import TemporaryFile"
      ],
      "metadata": {
        "id": "Va6ZaaR85NTB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports for models\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "1LqG6kzR-bSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python Functions For Data Preprocessing Pipeline"
      ],
      "metadata": {
        "id": "FIz_61q95f1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizes Individual Matrices\n",
        "def feature_normalize(data):\n",
        "  mean = data[data.nonzero()].mean()\n",
        "  sigma = data[data.nonzero()].std()\n",
        "  data_normalized = data\n",
        "  data_normalized[data_normalized.nonzero()] = (data_normalized[data_normalized.nonzero()] - mean)/sigma\n",
        "  return data_normalized"
      ],
      "metadata": {
        "id": "93-SxY-n5Vnf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizes entire 1D Dataset\n",
        "def norm_dataset(dataset_1D):\n",
        "  norm_dataset_1D = np.zeros([dataset_1D.shape[0], 16])\n",
        "  for i in range(dataset_1D.shape[0]):\n",
        "    norm_dataset_1D[i] =  feature_normalize(dataset_1D[i])\n",
        "  return norm_dataset_1D"
      ],
      "metadata": {
        "id": "fhVYb0bJ5sK4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turns data from 1D to 2D matrix\n",
        "# STILL 64 channel format\n",
        "# FUNCTION MEANT FOR OPENBCI HEADSET LAYOUT\n",
        "def data_1Dto2D(data, Y=10, X=11):\n",
        "\n",
        "  # initialize empty matrix to append to and return\n",
        "  full_matrix = np.empty((0, 10, 11))\n",
        "\n",
        "  # goes through every 1D timestamp and transforms to 2D spatial matrix\n",
        "  for i in range(len(data)):\n",
        "    data_2D = np.zeros([Y, X])\n",
        "\n",
        "    data_2D[0] = (0, 0, 0, 0, data[i][0], 0, data[i][1], 0, 0, 0, 0)\n",
        "    data_2D[1] = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
        "    data_2D[2] = (0, data[i][8], 0, data[i][10], 0, 0, 0, data[i][11], 0, data[i][9], 0)\n",
        "    data_2D[3] = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
        "    data_2D[4] = (0, data[i][12], 0, data[i][2], 0, 0, 0, data[i][3], 0, data[i][13], 0)\n",
        "    data_2D[5] = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
        "    data_2D[6] = (0, data[i][4], 0, data[i][14], 0, 0, 0, data[i][15], 0, data[i][5], 0)\n",
        "    data_2D[7] = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
        "    data_2D[8] = (0, 0, 0, 0, data[i][6], 0, data[i][7], 0, 0, 0, 0)\n",
        "    data_2D[9] = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
        "    \n",
        "    full_matrix = np.append(full_matrix, data_2D)\n",
        "\n",
        "  # reshape full_matrix to proper shape\n",
        "  full_matrix = full_matrix.reshape(len(data), 10, 11)\n",
        "\n",
        "  # return full matrix\n",
        "  return full_matrix"
      ],
      "metadata": {
        "id": "Lwg30uWb535Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffles two arrays in unison\n",
        "# To be used to randomize the cnn and rnn arrays together\n",
        "def unison_shuffle_arrays(arr_1, arr_2, arr_3):\n",
        "  if len(arr_1) != len(arr_2) or len(arr_1) != len(arr_3):\n",
        "    print('ERROR: The length of the two arrays are not equal.')\n",
        "    return -1\n",
        "  rp = np.random.permutation(len(arr_1))\n",
        "  return arr_1[rp], arr_2[rp], arr_3[rp]"
      ],
      "metadata": {
        "id": "pdIAnD_k6TxJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separates individual events into dataset\n",
        "# For the 30s len recordings\n",
        "def seperate_events_30s(data):\n",
        "  event_matrix = np.empty((0, 125, 10, 11))\n",
        "\n",
        "  # Separate each event from the data\n",
        "  event_1 = data[1125:1250]\n",
        "  event_2 = data[1375:1500]\n",
        "  event_3 = data[1625:1750]\n",
        "  event_4 = data[1875:2000]\n",
        "  event_5 = data[2125:2250]\n",
        "  event_6 = data[2375:2500]\n",
        "  event_7 = data[2625:2750]\n",
        "  event_8 = data[2875:3000]\n",
        "  event_9 = data[3125:3250]\n",
        "  event_10 = data[3375:3500]\n",
        "\n",
        "  # Append each event to event matrix\n",
        "  event_matrix = np.append(event_matrix, event_1)\n",
        "  event_matrix = np.append(event_matrix, event_2)\n",
        "  event_matrix = np.append(event_matrix, event_3)\n",
        "  event_matrix = np.append(event_matrix, event_4)\n",
        "  event_matrix = np.append(event_matrix, event_5)\n",
        "  event_matrix = np.append(event_matrix, event_6)\n",
        "  event_matrix = np.append(event_matrix, event_7)\n",
        "  event_matrix = np.append(event_matrix, event_8)\n",
        "  event_matrix = np.append(event_matrix, event_9)\n",
        "  event_matrix = np.append(event_matrix, event_10)\n",
        "\n",
        "  # Return event matrix\n",
        "  return event_matrix"
      ],
      "metadata": {
        "id": "4eERTSKM6fom"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN DRIVER FUNCTION: Saves to event array\n",
        "# file_list: list of files to be iterated through\n",
        "# events_per_file: 3 events for 16s files, 10 for 30s files\n",
        "# label: 0 for /x/, 1 for /y/\n",
        "def save_events(file_list, events_per_file, label):\n",
        "  \n",
        "  # Variable Init\n",
        "  event_labels = []\n",
        "  cnn_event_array = np.empty((0, 125, 10, 11))\n",
        "  rnn_event_array = np.empty((0, 125, 64))\n",
        "  total_events = 0\n",
        "  i = 0\n",
        "\n",
        "  for file in file_list:\n",
        "\n",
        "    # reads csv to data frame\n",
        "    df = pd.read_csv(file)\n",
        "  \n",
        "    # seperate channel data\n",
        "    channel_data = df[[\" EXG Channel 0\", \" EXG Channel 1\", \" EXG Channel 2\", \" EXG Channel 3\",\n",
        "                       \" EXG Channel 4\", \"EXG Channel 5\", \" EXG Channel 6\", \" EXG Channel 7\",\n",
        "                       \" EXG Channel 8\", \" EXG Channel 9\", \" EXG Channel 10\", \" EXG Channel 11\",\n",
        "                       \" EXG Channel 12\", \" EXG Channel 13\", \" EXG Channel 14\", \" EXG Channel 15\"]]\n",
        "    \n",
        "    # rename channel_data columns\n",
        "    channel_data = channel_data.rename({\" EXG Channel 0\":'1', \" EXG Channel 1\":'2', \" EXG Channel 2\":'3',\n",
        "                                        \" EXG Channel 3\":'4', \" EXG Channel 4\":'5', \" EXG Channel 5\":'6',\n",
        "                                        \" EXG Channel 6\":'7', \" EXG Channel 7\":'8', \" EXG Channel 8\":'9',\n",
        "                                        \" EXG Channel 9\":'10', \" EXG Channel 10\":'11', \" EXG Channel 11\":'12',\n",
        "                                        \" EXG Channel 12\":'13', \" EXG Channel 13\":'14', \" EXG Channel 14\":'15',\n",
        "                                        \" EXG Channel 15\":'16'}, axis='columns')\n",
        "\n",
        "    # turn channel_data into a np array\n",
        "    channel_data = channel_data.to_numpy()\n",
        "\n",
        "    # normalize channel_data\n",
        "    rnn_data = norm_dataset(channel_data)\n",
        "\n",
        "    # separation of events in rnn event array\n",
        "    rnn_events = seperate_events_30s(channel_data)\n",
        "\n",
        "    # transform channel data from 1D array to spatial matrices\n",
        "    channel_data = data_1Dto2D(channel_data)\n",
        "\n",
        "    # separation of events into event array\n",
        "    cnn_events = seperate_events_30s(channel_data)\n",
        "\n",
        "    # add events to total events for future reshaping\n",
        "    total_events = total_events + events_per_file\n",
        "\n",
        "    # append the rnn events array to event array\n",
        "    rnn_event_array = np.append(rnn_event_array, rnn_events)\n",
        "\n",
        "    # append the events array to event array\n",
        "    cnn_event_array = np.append(cnn_event_array, cnn_events)\n",
        "    print('File ' + str(i) + ' complete.')\n",
        "    \n",
        "    # add for count\n",
        "    i = i + 1\n",
        "\n",
        "  # reshape event arrays\n",
        "  rnn_event_array = rnn_event_array.reshape(total_events, 125, 16)\n",
        "  cnn_event_array = cnn_event_array.reshape(total_events, 125, 10, 11)\n",
        "\n",
        "  # make label array for the events\n",
        "  # label: 0 for X, 1 for Y\n",
        "  for n in range(total_events):\n",
        "    if(label == 0):\n",
        "      event_labels.append(0)\n",
        "    elif(label == 1):\n",
        "      event_labels.append(1)\n",
        "\n",
        "  print('labels array complete.')\n",
        "\n",
        "  # make a list to return both arrays\n",
        "  ret = [cnn_event_array, rnn_event_array, event_labels]\n",
        "\n",
        "  # return value for function\n",
        "  return ret"
      ],
      "metadata": {
        "id": "jyz2DHED6sD_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python Code for Reading the EEG Data into the python workspace"
      ],
      "metadata": {
        "id": "ngdm6BEH9NL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories of EEG data\n",
        "x_dir = r\"C:\\DIRECTORY-GOES-HERE\\Recordings\\x_files\\*\\*\"\n",
        "y_dir = r\"C:\\DIRECTORY-GOES-HERE\\Recordings\\y_files\\*\\*\""
      ],
      "metadata": {
        "id": "_OT-_BR_81Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization of file lists\n",
        "x_files = []\n",
        "y_files = []"
      ],
      "metadata": {
        "id": "bKMTI1fS9SuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Append files to file list\n",
        "for file in glob.glob(x_dir):\n",
        "  x_files.append(file)\n",
        "for file in glob.glob(y_dir):\n",
        "  y_files.append(file)"
      ],
      "metadata": {
        "id": "ZPzJI5wN9Sre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to event array (SEE save_events FUNCTION)\n",
        "# file_list: list of files to be iterated through\n",
        "# events_per_file: 10\n",
        "# label: 0 for X, 1 for Y\n",
        "x_arr = save_events(x_files, 10, 0)\n",
        "y_arr = save_events(y_files, 10, 1)"
      ],
      "metadata": {
        "id": "mO1E8OLC9SpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding event arrays together\n",
        "total_arr_len = len(x_arr[2]) + len(y_arr[2])"
      ],
      "metadata": {
        "id": "_xd1YOdN9Sk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization of empty arrays\n",
        "all_cnn_events_arr = np.empty((0, 125, 10, 11))\n",
        "all_rnn_events_arr = np.empty((0, 125, 16))\n",
        "all_labels_arr = np.empty((0))"
      ],
      "metadata": {
        "id": "EHqnGckX9See"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# append all cnn event arrays to all_cnn_event_arr\n",
        "all_cnn_events_arr = np.append(all_cnn_events_arr, x_arr[0])\n",
        "all_cnn_events_arr = np.append(all_cnn_events_arr, y_arr[0])"
      ],
      "metadata": {
        "id": "0isG-Oup9Sa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# append all rnn event arrays to all_rnn_event_arr\n",
        "all_rnn_events_arr = np.append(all_rnn_events_arr, x_arr[1])\n",
        "all_rnn_events_arr = np.append(all_rnn_events_arr, y_arr[1])"
      ],
      "metadata": {
        "id": "HH8Ce3by9SX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape arrays to maintain dimensions\n",
        "all_cnn_events_arr = all_cnn_events_arr.reshape(total_arr_len, 125, 10, 11)\n",
        "all_rnn_events_arr = all_rnn_events_arr.reshape(total_arr_len, 125, 16)"
      ],
      "metadata": {
        "id": "vKlNbvTO9SU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert labels to NumPy array\n",
        "x_arr_labels = np.asarray(x_arr[2])\n",
        "y_arr_labels = np.asarray(y_arr[2])"
      ],
      "metadata": {
        "id": "NiKs1ANj9SK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# append all labels to all_labels_arr\n",
        "all_labels_arr = np.append(all_labels_arr, x_arr_labels)\n",
        "all_labels_arr = np.append(all_labels_arr, y_arr_labels)"
      ],
      "metadata": {
        "id": "2HbrwVDg9tht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding Labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = np.array(label_encoder.fit_transform(all_labels_arr))"
      ],
      "metadata": {
        "id": "bKRybj_Q9te2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split"
      ],
      "metadata": {
        "id": "1BxJeuLX9xcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "split = np.random.rand(len(all_cnn_events_arr)) < 0.75"
      ],
      "metadata": {
        "id": "tx4H0QLk9tb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Data\n",
        "train_X_cnn = all_cnn_events_arr[split]\n",
        "train_X_rnn = all_rnn_events_arr[split]\n",
        "train_y = encoded_labels[split]\n",
        "\n",
        "# Test Data\n",
        "test_X_cnn = all_cnn_events_arr[~split]\n",
        "test_X_rnn = all_rnn_events_arr[~split]\n",
        "test_y = encoded_labels[~split]"
      ],
      "metadata": {
        "id": "SN-TLrGJ9tZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# randomize the data\n",
        "# return values:\n",
        "# 0 - cnn_events\n",
        "# 1 - rnn_events\n",
        "# 2 - labels\n",
        "randomized_train = unison_shuffle_arrays(train_X_cnn, train_X_rnn, train_y)\n",
        "randomized_test = unison_shuffle_arrays(test_X_cnn, test_X_rnn, test_y)"
      ],
      "metadata": {
        "id": "H_o4WX8-9tWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign return values\n",
        "train_X_cnn = randomized_train[0]\n",
        "train_X_rnn = randomized_train[1]\n",
        "train_y = randomized_train[2]\n",
        "\n",
        "test_X_cnn = randomized_test[0]\n",
        "test_X_rnn = randomized_test[1]\n",
        "test_y = randomized_test[2]"
      ],
      "metadata": {
        "id": "gEvzRSc29tUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand dimensions in Data for model read in\n",
        "train_X_cnn = tf.expand_dims(train_X_cnn, -1)\n",
        "test_X_cnn = tf.expand_dims(test_X_cnn, -1)"
      ],
      "metadata": {
        "id": "5OxHWNKp9tR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model 1: O’Neill et al. 3D-CNN-DNN**"
      ],
      "metadata": {
        "id": "O6OB4VGK-NV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "# 3D-CNN-DNN Model build                                         #\n",
        "##################################################################\n",
        "\n",
        "# Input\n",
        "a1_inputs = tf.keras.Input(shape = (125, 10, 11, 1))\n",
        "\n",
        "# 3-Layer 3D CNN\n",
        "a1_model = layers.Conv3D(32, kernel_size=(3, 3, 3), activation='relu')(a1_inputs)\n",
        "a1_model = layers.Conv3D(64, (3, 3, 3), activation = 'relu')(a1_model)\n",
        "a1_model = layers.Conv3D(128, (5, 4, 3), activation = 'relu')(a1_model)\n",
        "\n",
        "# Flatten to Dense\n",
        "a1_model = layers.Flatten()(a1_model)\n",
        "\n",
        "# FC Layers\n",
        "a1_model = layers.Dense(1024, activation='relu')(a1_model)\n",
        "a1_model = layers.Dense(1024, activation='relu')(a1_model)\n",
        "a1_model = layers.Dense(1024, activation='relu')(a1_model)\n",
        "\n",
        "# Softmax Output\n",
        "a1_outputs = layers.Dense(5, activation='softmax')(a1_model)\n",
        "\n",
        "# Model Creation\n",
        "a_3d_cnn = keras.Model(inputs=a1_inputs, outputs=a1_outputs)"
      ],
      "metadata": {
        "id": "pL_n_zCp9tPe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model 2: Zhang et al.’s Parallel CRNN**"
      ],
      "metadata": {
        "id": "CtP13kHk-6RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "# ZHANG et al.'s PARALLEL CRNN                                   #\n",
        "##################################################################\n",
        "\n",
        "# 3-Layer 2D CNN\n",
        "\n",
        "# Input: Spatial Matrices\n",
        "inputs_1 = tf.keras.Input(shape = (125, 10, 11, 1))\n",
        "\n",
        "# 2D CNN Layers\n",
        "model_1 = layers.Conv2D(32, (3, 3), activation='relu')(inputs_1)\n",
        "model_1 = layers.Conv2D(64, (3, 3), activation='relu')(model_1)\n",
        "model_1 = layers.Conv2D(128, (3, 2), activation='relu')(model_1)\n",
        "\n",
        "# Flatten CNN\n",
        "model_1 = layers.Flatten()(model_1)\n",
        "\n",
        "# CNN FC Layer\n",
        "model_1 = layers.Dense(1024, activation='relu')(model_1)\n",
        "\n",
        "##################################################################\n",
        "# 2-Layer LSTM RNN                                               #\n",
        "##################################################################\n",
        "\n",
        "# Input: Voltage-at-time array\n",
        "inputs_2 = tf.keras.Input(shape = (125, 16))\n",
        "\n",
        "# LSTM Layer 1\n",
        "model_2 = layers.LSTM(16, return_sequences = True)(inputs_2)\n",
        "\n",
        "# LSTM Layer 2\n",
        "model_2 = layers.LSTM(16)(model_2)\n",
        "\n",
        "# LSTM FC Layer\n",
        "model_2 = layers.Dense(1024)(model_2)\n",
        "\n",
        "##################################################################\n",
        "# Model Concatenation and output\n",
        "##################################################################\n",
        "\n",
        "# concat the RNN and the CNN\n",
        "model_concat = tf.concat([model_1, model_2], axis=1)\n",
        "\n",
        "# SoftMax Output\n",
        "outputs = layers.Dense(2, activation='softmax')(model_concat)\n",
        "\n",
        "# Model Creation\n",
        "parallel_crnn = keras.Model(inputs=[inputs_1, inputs_2], outputs=[outputs])"
      ],
      "metadata": {
        "id": "INDDlXik9tMG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model 3: Zhang et al.’s Cascade CRNN**"
      ],
      "metadata": {
        "id": "3QJyQrDS_vjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "# ZHANG et al.'s Cascade CRNN                                    #\n",
        "##################################################################\n",
        "\n",
        "# Input\n",
        "crnn_inputs = tf.keras.Input(shape = (125, 10, 11, 1))\n",
        "\n",
        "# 3-Layer 2D CNN\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(crnn_inputs)\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
        "\n",
        "# Flatten ConvNet Output\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "# Fully Connected layer\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "\n",
        "# Reshape Feature Vector to fit in LSTM cell\n",
        "x = layers.Reshape((1, x.shape[1]))(x)\n",
        "\n",
        "# 2-Layer LSTM RNN\n",
        "# Changing units to 1024 from 64, 16 (original) respectively\n",
        "x = layers.LSTM(1024, return_sequences = True)(x)\n",
        "x = layers.LSTM(1024)(x)\n",
        "\n",
        "# Output\n",
        "crnn_outputs = layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Model Creation\n",
        "cascade_crnn = keras.Model(inputs=crnn_inputs, outputs=crnn_outputs)"
      ],
      "metadata": {
        "id": "hS6tYFyJ9tJg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model 4: Modified Cecotti & Jha’s 4-Layer 3DCNN**"
      ],
      "metadata": {
        "id": "h7NfayI-AGn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "# (MODIFIED) Cecotti and Jha's 4-Layer 3DCNN                     #\n",
        "##################################################################\n",
        "\n",
        "# Input\n",
        "c4_inputs = tf.keras.Input(shape = (125, 10, 11, 1))\n",
        "\n",
        "# 4-Layer 3D CNN\n",
        "c4_model = layers.Conv3D(32, kernel_size=(3, 3, 3), activation='relu')(c4_inputs)\n",
        "c4_model = layers.Conv3D(64, (3, 3, 3), activation = 'relu')(c4_model)\n",
        "c4_model = layers.Conv3D(128, (3, 3, 3), activation = 'relu')(c4_model)\n",
        "c4_model = layers.Conv3D(256, (3, 2, 3), activation = 'relu')(c4_model)\n",
        "\n",
        "# Flatten to Dense\n",
        "c4_model = layers.Flatten()(c4_model)\n",
        "\n",
        "# FC Layers (DNN)\n",
        "c4_model = layers.Dense(1024, activation='relu')(c4_model)\n",
        "c4_model = layers.Dense(1024, activation='relu')(c4_model)\n",
        "c4_model = layers.Dense(1024, activation='relu')(c4_model)\n",
        "\n",
        "# SoftMax Output\n",
        "c4_outputs = layers.Dense(2, activation='softmax')(c4_model)\n",
        "\n",
        "# Model Creation\n",
        "c4_3d_cnn = keras.Model(inputs=c4_inputs, outputs=c4_outputs)"
      ],
      "metadata": {
        "id": "hQu6DJGB9tES"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model 5: Liu et al.’s CNN-SAE-DNN**"
      ],
      "metadata": {
        "id": "dLkJME6WAnoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "# Liu et al/'s CNN-SAE-DNN                                       #\n",
        "##################################################################\n",
        "# Input\n",
        "inputs = tf.keras.Input(shape = (125, 10, 11))\n",
        "\n",
        "# 2D CNN\n",
        "model = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "model = layers.Conv2D(64, (3, 3), activation='relu')(model)\n",
        "\n",
        "# Flatten into SAE\n",
        "model = layers.Flatten()(model)\n",
        "\n",
        "# SAE\n",
        "model = layers.Dense(5120, activation='relu')(model)\n",
        "model = layers.Dense(120, activation='relu')(model)\n",
        "model = layers.Dense(5120, activation='relu')(model)\n",
        "\n",
        "# DNN\n",
        "model = layers.Dense(1024, activation='relu')(model)\n",
        "model = layers.Dense(1024, activation='relu')(model)\n",
        "model = layers.Dense(1024, activation='relu')(model)\n",
        "\n",
        "# Softmax Output\n",
        "outputs = layers.Dense(2, activation='softmax')(model)\n",
        "\n",
        "# Model Creation\n",
        "liu_model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "rYpOReaMAmSJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "irvT9pp-A9PK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}